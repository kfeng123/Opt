\documentclass[11pt, letterpaper]{article}
 
\usepackage{lineno,hyperref}

\usepackage{galois} % composition function \comp
\usepackage{bm}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathrsfs}
\usepackage{amsthm}
\usepackage{natbib}
\usepackage{graphicx}
\usepackage{color}
\usepackage{booktabs}
\usepackage[page,title]{appendix}
%\renewcommand\appendixname{haha}
\usepackage{enumerate}
\usepackage{changepage}
\usepackage{datetime}
\newdate{date}{9}{1}{2017}

%%%%%%%%  page setup %%%%%%%%
\textheight 8.5 in
\textwidth 6.5 in
\topmargin -0.5 in
\oddsidemargin -0.1 in

%%%%%%%%%%%%%%  Notations %%%%%%%%%%
\DeclareMathOperator{\mytr}{tr}
\DeclareMathOperator{\mydiag}{diag}
\DeclareMathOperator{\myrank}{Rank}
\DeclareMathOperator{\myP}{P}
\DeclareMathOperator{\myE}{E}
\DeclareMathOperator{\myVar}{Var}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}


\newcommand{\Ba}{\mathbf{a}}    \newcommand{\Bb}{\mathbf{b}}    \newcommand{\Bc}{\mathbf{c}}    \newcommand{\Bd}{\mathbf{d}}    \newcommand{\Be}{\mathbf{e}}    \newcommand{\Bf}{\mathbf{f}}    \newcommand{\Bg}{\mathbf{g}}    \newcommand{\Bh}{\mathbf{h}}    \newcommand{\Bi}{\mathbf{i}}    \newcommand{\Bj}{\mathbf{j}}    \newcommand{\Bk}{\mathbf{k}}    \newcommand{\Bl}{\mathbf{l}}
\newcommand{\Bm}{\mathbf{m}}    \newcommand{\Bn}{\mathbf{n}}    \newcommand{\Bo}{\mathbf{o}}    \newcommand{\Bp}{\mathbf{p}}    \newcommand{\Bq}{\mathbf{q}}    \newcommand{\Br}{\mathbf{r}}    \newcommand{\Bs}{\mathbf{s}}    \newcommand{\Bt}{\mathbf{t}}    \newcommand{\Bu}{\mathbf{u}}    \newcommand{\Bv}{\mathbf{v}}    \newcommand{\Bw}{\mathbf{w}}    \newcommand{\Bx}{\mathbf{x}}
\newcommand{\By}{\mathbf{y}}    \newcommand{\Bz}{\mathbf{z}}    
\newcommand{\BA}{\mathbf{A}}    \newcommand{\BB}{\mathbf{B}}    \newcommand{\BC}{\mathbf{C}}    \newcommand{\BD}{\mathbf{D}}    \newcommand{\BE}{\mathbf{E}}    \newcommand{\BF}{\mathbf{F}}    \newcommand{\BG}{\mathbf{G}}    \newcommand{\BH}{\mathbf{H}}    \newcommand{\BI}{\mathbf{I}}    \newcommand{\BJ}{\mathbf{J}}    \newcommand{\BK}{\mathbf{K}}    \newcommand{\BL}{\mathbf{L}}
\newcommand{\BM}{\mathbf{M}}    \newcommand{\BN}{\mathbf{N}}    \newcommand{\BO}{\mathbf{O}}    \newcommand{\BP}{\mathbf{P}}    \newcommand{\BQ}{\mathbf{Q}}    \newcommand{\BR}{\mathbf{R}}    \newcommand{\BS}{\mathbf{S}}    \newcommand{\BT}{\mathbf{T}}    \newcommand{\BU}{\mathbf{U}}    \newcommand{\BV}{\mathbf{V}}    \newcommand{\BW}{\mathbf{W}}    \newcommand{\BX}{\mathbf{X}}
\newcommand{\BY}{\mathbf{Y}}    \newcommand{\BZ}{\mathbf{Z}}    

\newcommand{\bfsym}[1]{\ensuremath{\boldsymbol{#1}}}

 \def\balpha{\bfsym \alpha}
 \def\bbeta{\bfsym \beta}
 \def\bgamma{\bfsym \gamma}             \def\bGamma{\bfsym \Gamma}
 \def\bdelta{\bfsym {\delta}}           \def\bDelta {\bfsym {\Delta}}
 \def\bfeta{\bfsym {\eta}}              \def\bfEta {\bfsym {\Eta}}
 \def\bmu{\bfsym {\mu}}                 \def\bMu {\bfsym {\Mu}}
 \def\bnu{\bfsym {\nu}}
 \def\btheta{\bfsym {\theta}}           \def\bTheta {\bfsym {\Theta}}
 \def\beps{\bfsym \varepsilon}          \def\bepsilon{\bfsym \varepsilon}
 \def\bsigma{\bfsym \sigma}             \def\bSigma{\bfsym \Sigma}
 \def\blambda {\bfsym {\lambda}}        \def\bLambda {\bfsym {\Lambda}}
 \def\bomega {\bfsym {\omega}}          \def\bOmega {\bfsym {\Omega}}
 \def\brho   {\bfsym {\rho}}
 \def\btau{\bfsym {\tau}}
 \def\bxi{\bfsym {\xi}}
 \def\bzeta{\bfsym {\zeta}}
% May add more in future.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\theoremstyle{plain}
\newtheorem{theorem}{\quad\quad Theorem}
\newtheorem{proposition}{\quad\quad Proposition}
\newtheorem{corollary}{\quad\quad Corollary}
\newtheorem{lemma}{\quad\quad Lemma}
\newtheorem{example}{Example}
\newtheorem{assumption}{\quad\quad Assumption}
\newtheorem{condition}{\quad\quad Condition}

\theoremstyle{definition}
\newtheorem{remark}{\quad\quad Remark}
\theoremstyle{remark}


\begin{document}
\title{Some Theory of Likelihood}
\maketitle
\section{To be done}
\begin{itemize}
    \item
        Give the theory of posterior Bayes factor under exponential family.
    \item
        Beyond exponential family.~\citep{berger2003approximations}.
    \item
        Neyman-Scott problems.
    \item
        Bartlett correction.
    \item
    General integral likelihood ratio test.
    \item
        Nonasymptotic. Read~\cite{spokoiny2012parametric}'s paper.
    \item
    Consider the sparse case as in~\cite{stadler2016two}.
\end{itemize}
\section{Introduction}

\section{Results for exponential family}
The content of this section is adapted from~\cite{Ghosal2000Asymptotic}.

The following result, known as acute angle principle, is a key tool for the analysis.
\begin{lemma}[~\cite{book:263774}, Theorem 6.3.4.]\label{acute}
    Let $C$ be an open, bounded set in $\mathbb{R}^n$ and assume that $F:\bar{C}\subset \mathbb{R}^n \mapsto \mathbb{R}^n$ is countinuous and satisfies $(x-x_0)^T F(x)\geq 0$ for some $x_0\in C$ and all $x\in \partial C$. Then $F(x)=0$ has a solution in $\bar{C}$.
\end{lemma}

We make the following assumptions.
\begin{assumption}\label{model}
    The $p$ dimensional independent random samples $X_1,\ldots, X_n$ are from a standard exponential family with density
    $$f(x;\theta_n)=\exp[x^T \theta_n-\psi_n(\theta_n)]$$ 
    with respect to $\mu_n$.
    Where $\theta_n\in\Theta_n$, an \textbf{open} subset of $\mathbb{R}^n$.
    Sometimes we suppress the subscript $n$.

    The true parameter is denoted by $\theta_0$.
    {\color{red}To prevent $\theta_0$ approaching the boundary as $n\to \infty$, we assume that for a fixed $\epsilon_0>0$ independent of n, $B(\theta_0,\epsilon_0)\subset \Theta$.}


    It's well known that $\myE X_1=\psi'(\theta_0)$ and $\myVar X_1=\psi''(\theta_0)$. $\psi''(\theta_0)$ is also the Fisher information matrix. We assume that $\psi''(\theta_0)$ is positive definite.
\end{assumption}
\begin{assumption}\label{pAndN}
$p\to \infty$ as $n\to \infty$.
\end{assumption}

Let the positive definite matrix $\BJ$ be the  square root of $\psi''(\theta_0)$, that is $\psi''(\theta_0)=\BJ^2$.
The MLE $\hat{\theta}$ of $\theta$ is unique and satisfies $\psi'(\hat{\theta})=\bar{X}$.

For a square matrix $\BA$, $\|\BA\|$ will stand for its operator norm.

The function $\psi(\theta)$ is in fact the cumulant generating function of $X_1$. 
\cite{portnoy1988asymptotic} gave the following Taylor series expansions.
\begin{proposition}\label{Taylor}
    Suppose Assumption~\ref{model} holds.
    For any $\theta$ and $\theta_0$ in $\Theta$, the following expansions hold for some $\tilde{\theta}$ between $\theta$ and $\theta_0$:
    $$
    \begin{aligned}
        \psi(\theta)=&\psi(\theta_0)+(\theta-\theta_0)^T \psi'(\theta_0)+\frac{1}{2}(\theta-\theta_0)^T \psi''(\theta_0) (\theta-\theta_0)\\
        &+\frac{1}{6}\myE_{\theta_0}\Big((\theta-\theta_0)^T (U-\myE_{\theta_0}U)\Big)^3\\
        &+\frac{1}{24}\Big\{
            \myE_{\tilde{\theta}}\Big((\theta-\theta_0)^T (U-\myE_{\tilde\theta}U)\Big)^4-
            3\big[\myE_{\tilde{\theta}}\big((\theta-\theta_0)^T (U-\myE_{\tilde\theta}U)\big)^2\big]^2
            \Big\},
    \end{aligned}
    $$
    $$
    \begin{aligned}
        \alpha^T\psi'(\theta)=&\alpha^T \psi'(\theta_0)+\alpha^T \psi''(\theta_0) (\theta-\theta_0)\\
        &+\frac{1}{2}\myE_{\theta_0}\big((\theta-\theta_0)^T (U-\myE_{\theta_0}U)\big)^2 \alpha^T (U-\myE_{\theta_0}U)\\
        &+\frac{1}{6}
            \myE_{\tilde{\theta}}\big((\theta-\theta_0)^T (U-\myE_{\tilde\theta}U)\big)^3 \alpha^T (U-\myE_{\tilde\theta}U)\\
            &-\frac{1}{2}
            \myE_{\tilde{\theta}}\big((\theta-\theta_0)^T (U-\myE_{\tilde\theta}U)\big)^2
            \myE_{\tilde{\theta}}(\theta-\theta_0)^T (U-\myE_{\tilde\theta}U) \alpha^T (U-\myE_{\tilde\theta}U),
    \end{aligned}
    $$
    $$
    \begin{aligned}
        \alpha^T\psi'(\theta)=&\alpha^T \psi'(\theta_0)+\alpha^T \psi''(\theta_0) (\theta-\theta_0)
        +\frac{1}{2}\myE_{\tilde\theta}\big((\theta-\theta_0)^T (U-\myE_{\tilde\theta}U)\big)^2 \alpha^T (U-\myE_{\tilde\theta}U),
    \end{aligned}
    $$
    where $U$ is a random variable with density $f(x;\theta)$, $\alpha$ is a fixed $p$ dimensional vector.
\end{proposition}

Let, for $c\geq 0$,
$$
\begin{aligned}
    B_{1n}(c)&=\sup\Big\{\myE_{\theta}|a^T \BJ^{-1}(U-\myE_\theta U)|^3: \|a\|=1, \|\BJ(\theta-\theta_0)\|\leq c\Big\},\\
    B_{2n}(c)&=\sup\Big\{\myE_{\theta}|a^T \BJ^{-1}(U-\myE_\theta U)|^4: \|a\|=1, \|\BJ(\theta-\theta_0)\|\leq c\Big\},
\end{aligned}
$$

Consistency.
\begin{theorem}\label{TheoremConsistency}
    Suppose Assumption~\ref{model} holds.
    Assume that for every $M>0$, we have $\{\theta:\|\BJ(\theta-\theta_0)\|\leq M\sqrt{p/n} \}\subset \Theta$ for large $n$.
    Assume that for all $M>0$, $M\sqrt{p/n}B_{1n}(M\sqrt{p/n})\to 0$.
    Then
    $$\|\BJ(\hat{\theta}-\theta_0)\|=O_P(\sqrt{p/n}).$$
\end{theorem}
\begin{proof}
    The MLE $\hat{\theta}$ is unique and satisfies $\bar{X}-\psi'(\hat{\theta})=0$.
    By Lemma~\ref{acute}, the inequality 
    $$\sup_{\|\BJ(\theta-\theta_0)\|=c}(\theta-\theta_0)^T(\bar{X}-\psi'(\theta))\leq 0$$
    implies $\|\BJ(\hat{\theta}-\theta_0)\|\leq c$.
    By proposition~\ref{Taylor}, for $\theta$ satisfying $\|\BJ(\theta-\theta_0)\|=c$, we have
    $$
    \begin{aligned}
        (\theta-\theta_0)^T(\bar{X}-\psi'(\theta))&=
    (\theta-\theta_0)^T(\bar{X}-\psi' (\theta_0))
    -(\theta-\theta_0)^T \psi''(\theta_0)(\theta-\theta_0)
        -\frac{1}{2}\myE_{\tilde\theta}\big((\theta-\theta_0)^T (U-\myE_{\tilde\theta}U)\big)^3\\
        &=
        (\theta-\theta_0)^T \BJ \BJ^{-1}(\bar{X}-\psi' (\theta_0))
        -c^2
        -\frac{1}{2}\myE_{\tilde\theta}\big((\theta-\theta_0)^T (U-\myE_{\tilde\theta}U)\big)^3\\
        &\leq
        c \|\BJ^{-1}(\bar{X}-\psi' (\theta_0))\|
        -c^2
        -\frac{1}{2}\myE_{\tilde\theta}\big((\theta-\theta_0)^T \BJ \BJ^{-1} (U-\myE_{\tilde\theta}U)\big)^3\\
        &\leq
        c \|\BJ^{-1}(\bar{X}-\psi' (\theta_0))\|
        -c^2
        +\frac{1}{2} c^3 B_{1n}(c).
    \end{aligned}
    $$
    Since $\myE\|\BJ^{-1}(\bar{X}-\psi' (\theta_0))\|^2=\mytr \myVar (\BJ^{-1}\bar{X})=p/n$, we have $\|\BJ^{-1}(\bar{X}-\psi' (\theta_0))\|=O_P(\sqrt{p/n})$.
    Hence for every $\delta>0$, there is an $M$ such that $\|\BJ^{-1}(\bar{X}-\psi' (\theta_0))\|\leq M\sqrt{p/n}$ with probability at least $1-\delta$.
    Taking $c=2M\sqrt{p/n}$ yields that with probability at least $1-\delta$,
    $$
        \sup_{\|\BJ(\theta-\theta_0)\|=M\sqrt{p/n}}(\theta-\theta_0)^T(\bar{X}-\psi'(\theta))\leq -2 M^2 \frac{p}{n}+ 2 M^2 \frac{p}{n} \Big(2M\sqrt{p/n}B_{1n}(2M\sqrt{p/n})\Big),
    $$
    which is less than $0$ eventually.
    Hence for large $n$, with probability at least $1-\delta$, $\|\BJ(\theta-\theta_0)\|\leq M\sqrt{p/n}$.
    This proves $\|\BJ(\theta-\theta_0)\|=O_P(\sqrt{p/n})$.

\end{proof}

\begin{proposition}\label{MLEexpansion}
    Suppose that Assumption~\ref{model} holds. Let $\hat{\theta}$ be the MLE.
    Then on the event  $\{\hat{\theta}\in \Theta\}$, for any $\alpha\in \mathbb{R}^p$, we have
    $$
    \begin{aligned}
        \alpha^T \BJ (\hat{\theta}-\theta_0)=&\alpha^T \BJ^{-1}(\bar{X}-\psi'(\theta_0))-\frac{1}{2}\myE_{U,\theta_0}\big((\hat{\theta}-\theta_0)^T \BJ \BJ^{-1}(U-\myE_{\theta_0}U)\big)^2 \alpha^T \BJ^{-1}(U-\myE_{\theta_0}U)\\
        &+O(1)\|\BJ (\hat{\theta}-\theta_0)\|^3 \|\alpha\| B_{2n}(\|\BJ (\hat{\theta}-\theta_0)\|),
    \end{aligned}
    $$
    where $|O(1)|\leq 2/3$.
\end{proposition}
\begin{proof}
    The MLE $\hat{\theta}$ satisfies $\alpha^T \BJ^{-1}\bar{X}=\alpha^T \BJ^{-1}\psi'(\hat{\theta}))$. Applying Proposition~\ref{Taylor} yields
    $$
    \begin{aligned}
        \alpha^T \BJ^{-1}\bar{X}=&\alpha^T \BJ^{-1}\psi'(\hat{\theta}))\\
        =&\alpha^T \BJ^{-1}\psi'(\theta_0)+\alpha^T \BJ (\hat{\theta}-\theta_0)\\
        &+\frac{1}{2}\myE_{U,\theta_0}\big((\hat{\theta}-\theta_0)^T \BJ \BJ^{-1}(U-\myE_{\theta_0}U)\big)^2 \alpha^T \BJ^{-1}(U-\myE_{\theta_0}U)\\
        &+\frac{1}{6}\myE_{U,\tilde{\theta}}\big((\hat{\theta}-\theta_0)^T \BJ \BJ^{-1} (U-\myE_{\tilde{\theta}}U) \big)^3 \alpha^T \BJ^{-1}(U-\myE_{\tilde{\theta}}U)\\
        &-\frac{1}{2}\myE_{U,\tilde{\theta}}\big((\hat{\theta}-\theta_0)^T \BJ \BJ^{-1}(U-\myE_{\tilde{\theta}}U)\big)^2 \myE_{U,\tilde{\theta}}(\hat{\theta}-\theta_0)^T \BJ \BJ^{-1}(U-\myE_{\tilde{\theta}}U) \alpha^T \BJ^{-1}(U-\myE_{\hat{\theta}}U).
    \end{aligned}
    $$
    For the second last term, we have
    $$
    \begin{aligned}
        &\myE_{U,\tilde{\theta}}\big((\hat{\theta}-\theta_0)^T \BJ \BJ^{-1} (U-\myE_{\tilde{\theta}}U) \big)^3 \alpha^T \BJ^{-1}(U-\myE_{\tilde{\theta}}U)\\
        \leq & \|\BJ (\hat{\theta}-\theta_0)\|^3 \|\alpha\|\sup_{\|a\|=1,\|b\|=1}\big|a^T \BJ^{-1}(U-\myE_{\tilde{\theta}} U)\big|^3 \big| b^T \BJ^{-1}(U-\myE_{\tilde{\theta}}U)\big|\\
        \leq & \|\BJ (\hat{\theta}-\theta_0)\|^3 \|\alpha\|\sup_{\|a\|=1}\big|a^T \BJ^{-1}(U-\myE_{\tilde{\theta}} U)\big|^4\\
        \leq & \|\BJ (\hat{\theta}-\theta_0)\|^3 \|\alpha\| B_{2n}(\|\BJ (\hat{\theta}-\theta_0)\|).
    \end{aligned}
    $$
    The last term satisfies the same bound. This proves the proposition.


\end{proof}

\begin{theorem}
    Suppose that Assumption~\ref{model} holds. Let $\hat{\theta}$ be the MLE.
    Then on the event  $\{\hat{\theta}\in \Theta\}$, for any $\alpha\in \mathbb{R}^p$, we have 
    $$
    \big|\sqrt{n}\alpha^T \BJ (\hat{\theta}-\theta_0)-\sqrt{n}\alpha^T \BJ^{-1}(\bar{X}-\psi'(\theta_0))\big|\leq
    \frac{\|\alpha\|}{2}\sqrt{n}\|\BJ (\hat{\theta}-\theta_0)\|^2 B_{1n}(0)+
    \frac{2\|\alpha\|}{3}\sqrt{n}\|\BJ(\hat{\theta}-\theta_0)\|^3 B_{2n}(\|\BJ(\hat{\theta}-\theta_0)\|).
    $$
    Furthermore, we have
    $$
    \begin{aligned}
    \big\|\sqrt{n}\BJ(\hat{\theta}-\theta_0)-\sqrt{n}\BJ^{-1}(\bar{X}-\psi'(\theta_0))\big\|^2 \leq
        &        2 n \|\BJ (\hat{\theta}-\theta_0)\|^3\|\BJ^{-1}(\bar{X}-\psi'(\theta_0))\| B_{2n}(\|\BJ(\hat{\theta}-\theta_0)\|)\\
        &+ 2 n\|\BJ(\hat{\theta}-\theta_0)\|^4 B_{2n}(\|\BJ (\hat{\theta}-\theta_0)\|).
    \end{aligned}
    $$
\end{theorem}
\begin{proof}
    The first assertion follows directly from Proposition~\ref{MLEexpansion}.
    Next we prove the second assertion.
    Write
    $$
    \begin{aligned}
        &\big\|\sqrt{n}\BJ(\hat{\theta}-\theta_0)-\sqrt{n}\BJ^{-1}(\bar{X}-\psi'(\theta_0))\big\|^2 \\
        =& n\|\BJ(\hat{\theta}-\theta_0)\|^2-2n(\hat{\theta}-\theta_0)^T \BJ \BJ^{-1}(\bar{X}-\psi'(\theta_0))+n\|\BJ^{-1}(\bar{X}-\psi'(\theta_0))\|^2.
    \end{aligned}
    $$
    For the first term, using Proposition~\ref{MLEexpansion} with $\alpha=n\BJ(\hat{\theta}-\theta_0)$, we have
    $$
    \begin{aligned}
        n\|\BJ(\hat{\theta}-\theta_0)\|^2=&n (\hat{\theta}-\theta_0)^T \BJ \BJ^{-1}(\bar{X}-\psi'(\theta_0))-\frac{n}{2}\myE_{U,\theta_0}\big((\hat{\theta}-\theta_0)^T \BJ \BJ^{-1}(U-\myE_{\theta_0}U)\big)^3\\
        &+O(1)n\|\BJ(\hat{\theta}-\theta_0)\|^4 B_{2n}(\|\BJ (\hat{\theta}-\theta_0)\|).
    \end{aligned}
    $$
    Therefore,
    $$
    \begin{aligned}
        &\big\|\sqrt{n}\BJ(\hat{\theta}-\theta_0)-\sqrt{n}\BJ^{-1}(\bar{X}-\psi'(\theta_0))\big\|^2 \\
        =&-n(\hat{\theta}-\theta_0)^T \BJ \BJ^{-1}(\bar{X}-\psi'(\theta_0))+n\|\BJ^{-1}(\bar{X}-\psi'(\theta_0))\|^2\\
        &-\frac{n}{2}\myE_{U,\theta_0}\big((\hat{\theta}-\theta_0)^T \BJ \BJ^{-1}(U-\myE_{\theta_0}U)\big)^3
        +O(1)n\|\BJ(\hat{\theta}-\theta_0)\|^4 B_{2n}(\|\BJ (\hat{\theta}-\theta_0)\|).
    \end{aligned}
    $$
    For the first term, using Proposition~\ref{MLEexpansion} with $\alpha=n\BJ^{-1}(\bar{X}-\psi'(\theta_0))$, we have
    $$
    \begin{aligned}
        &n(\hat{\theta}-\theta_0)^T \BJ \BJ^{-1}(\bar{X}-\psi'(\theta_0))\\
        =&n\|\BJ^{-1}(\bar{X}-\psi'(\theta_0))\|^2\\
        &-\frac{n}{2}\myE_{U,\theta_0}\big((\hat{\theta}-\theta_0)^T \BJ \BJ^{-1}(U-\myE_{\theta_0}U)\big)^2 (\bar{X}-\psi'(\theta_0))^T \BJ^{-2}(U-\myE_{\theta_0}U)\\
        &+O(1) n \|\BJ (\hat{\theta}-\theta_0)\|^3\|\BJ^{-1}(\bar{X}-\psi'(\theta_0))\| B_{2n}(\|\BJ(\hat{\theta}-\theta_0)\|).
    \end{aligned}
    $$
    Thus,
    $$
    \begin{aligned}
        &\big\|\sqrt{n}\BJ(\hat{\theta}-\theta_0)-\sqrt{n}\BJ^{-1}(\bar{X}-\psi'(\theta_0))\big\|^2 \\
        =&
        \frac{n}{2}\myE_{U,\theta_0}\big((\hat{\theta}-\theta_0)^T \BJ \BJ^{-1}(U-\myE_{\theta_0}U)\big)^2 (\bar{X}-\psi'(\theta_0))^T \BJ^{-2}(U-\myE_{\theta_0}U)\\
        &+O(1) n \|\BJ (\hat{\theta}-\theta_0)\|^3\|\BJ^{-1}(\bar{X}-\psi'(\theta_0))\| B_{2n}(\|\BJ(\hat{\theta}-\theta_0)\|)\\
        &-\frac{n}{2}\myE_{U,\theta_0}\big((\hat{\theta}-\theta_0)^T \BJ \BJ^{-1}(U-\myE_{\theta_0}U)\big)^3
        +O(1)n\|\BJ(\hat{\theta}-\theta_0)\|^4 B_{2n}(\|\BJ (\hat{\theta}-\theta_0)\|)\\
        =&
        \frac{n}{2}\myE_{U,\theta_0}\big((\hat{\theta}-\theta_0)^T \BJ \BJ^{-1}(U-\myE_{\theta_0}U)\big)^2 \big(\BJ^{-1}(\bar{X}-\psi'(\theta_0)) -\BJ (\hat{\theta}-\theta_0) \big)^T \BJ^{-1}(U-\myE_{\theta_0}U)\\ 
        &+O(1) n \|\BJ (\hat{\theta}-\theta_0)\|^3\|\BJ^{-1}(\bar{X}-\psi'(\theta_0))\| B_{2n}(\|\BJ(\hat{\theta}-\theta_0)\|)\\
        &+O(1)n\|\BJ(\hat{\theta}-\theta_0)\|^4 B_{2n}(\|\BJ (\hat{\theta}-\theta_0)\|)\\
        \leq&
        \frac{n}{2}\Big(\myE_{U,\theta_0}\big((\hat{\theta}-\theta_0)^T \BJ \BJ^{-1}(U-\myE_{\theta_0}U)\big)^4\Big)^{1/2} \Big(\myE_{U,\theta_0}\big(\big(\BJ^{-1}(\bar{X}-\psi'(\theta_0)) -\BJ (\hat{\theta}-\theta_0) \big)^T \BJ^{-1}(U-\myE_{\theta_0}U)\big)^2\Big)^{1/2}\\ 
        &+\frac{2}{3} n \|\BJ (\hat{\theta}-\theta_0)\|^3\|\BJ^{-1}(\bar{X}-\psi'(\theta_0))\| B_{2n}(\|\BJ(\hat{\theta}-\theta_0)\|)\\
        &+\frac{2}{3} n\|\BJ(\hat{\theta}-\theta_0)\|^4 B_{2n}(\|\BJ (\hat{\theta}-\theta_0)\|)\\
        \leq&
        \frac{1}{2}\Big(n\|\BJ(\hat{\theta}-\theta_0)\|^4 B_{2n}(0)\Big)^{1/2} \Big(n\big\|\big(\BJ^{-1}(\bar{X}-\psi'(\theta_0)) -\BJ (\hat{\theta}-\theta_0) \big\|^2 \Big)^{1/2}\\ 
        &+\frac{2}{3} n \|\BJ (\hat{\theta}-\theta_0)\|^3\|\BJ^{-1}(\bar{X}-\psi'(\theta_0))\| B_{2n}(\|\BJ(\hat{\theta}-\theta_0)\|)\\
        &+\frac{2}{3} n\|\BJ(\hat{\theta}-\theta_0)\|^4 B_{2n}(\|\BJ (\hat{\theta}-\theta_0)\|).
    \end{aligned}
    $$
    Let
    $
        \epsilon= n \|\BJ (\hat{\theta}-\theta_0)\|^3\|\BJ^{-1}(\bar{X}-\psi'(\theta_0))\| B_{2n}(\|\BJ(\hat{\theta}-\theta_0)\|)
        + n\|\BJ(\hat{\theta}-\theta_0)\|^4 B_{2n}(\|\BJ (\hat{\theta}-\theta_0)\|)
    $.
    Then 
    $$\big\|\sqrt{n}\BJ(\hat{\theta}-\theta_0)-\sqrt{n}\BJ^{-1}(\bar{X}-\psi'(\theta_0))\big\|^2 \leq \frac{1}{2}\sqrt{\epsilon} \big\|\sqrt{n}\BJ(\hat{\theta}-\theta_0)-\sqrt{n}\BJ^{-1}(\bar{X}-\psi'(\theta_0))\big\|+\frac{2}{3}\epsilon.$$
    Thus
    $
    \big\|\sqrt{n}\BJ(\hat{\theta}-\theta_0)-\sqrt{n}\BJ^{-1}(\bar{X}-\psi'(\theta_0))\big\|^2\leq 2\epsilon.
    $
\end{proof}


Next we consider the asymptotic normality of posterior distribution.
Let $\pi(\theta)$ be the prior density with respect to Lebesgue measure.
Then the posterior density of $\theta$ is given by
$$
\frac{
    f(x;\theta) \pi(\theta)
}{
    \int f(x;\theta) \pi(\theta)\, d \theta
}
$$
Put $u=\sqrt{n} \BJ (\theta-\theta_0)$.
The likelihood ratio, as a function of $u$, is given by
$$
Z_n(u)=\frac{f(x;\theta_0+n^{-1/2}\BJ^{-1}u)}{f(x;\theta_0)}.
$$
And the posterior density of $u$ is given by
$$
\pi^*(u)=\frac{
Z_n(u) \pi(\theta_0+n^{-1/2} \BJ^{-1}u)
}{
    \int Z_n(u) \pi(\theta_0+n^{-1/2} \BJ^{-1}u) \, du
}.
$$

Let $\Delta_n=\sqrt{n}\BJ^{-1}(\bar{X}-\mu)$. We have
$$
\begin{aligned}
    \log Z(u)=& \sqrt{n}\bar{X}^T \BJ^{-1}u-n(\psi(\theta_0+n^{-1/2}\BJ^{-1}u)-\psi(\theta_0))\\
    =&\Delta_n^T u-n\big(\psi(\theta_0+n^{-1/2}\BJ^{-1}u)-\psi(\theta_0)-n^{-1/2}\mu^T \BJ^{-1}u\big)\\
    =&\Delta_n^T u-\frac{1}{2}\|u\|^2-n\big(\psi(\theta_0+n^{-1/2}\BJ^{-1}u)-\psi(\theta_0)-n^{-1/2}\mu^T \BJ^{-1}u-n^{-1}\frac{1}{2} \|u\|^2\big).
\end{aligned}
$$
If the smaller order terms can be omitted, then the posterior density of $u$ is approximately $\phi_p(u;\Delta_n,\BI_p)$, where $\phi_p(\cdot;\mu,\Sigma)$ stands for the density of $N_p(\mu,\Sigma)$.
The following theorem makes this assertion rigorous.
\begin{theorem}[Asymptotic normality of posterior distribution]
    Suppose Assumption~\ref{model} holds.
    Let $C$ be a quantity satisfying $C\gg \sqrt{p}$.
    Suppose that for large $n$, $\{\theta: \|\BJ (\theta-\theta_0)\|\leq n^{-1/2} C\}\subset \Theta$.
Suppose that $\frac{1}{3}\big(\frac{1}{n^{1/2}}C B_{1n}(0)+\frac{1}{n}C^2 B_{2n}(n^{-1/2}C)\big)\leq 1/2$ for sufficiently large $n$.
    Then for any $\epsilon>0$, for sufficiently large $n$, with probability larger than $1-\epsilon$, 
    $$
    \begin{aligned}
    &\int | \pi^*(u) -\phi_p(u;\Delta_n,\BI_p)| \, du\\
    \leq&
      \Big|
      \exp\Big\{\frac{1}{6}\big(
    \frac{1}{n^{1/2}}C^3 B_{1n}(0)+\frac{1}{n}C^4 B_{2n}(n^{-1/2}C)
      \big)\Big\}
        -
        1
          \Big| 
      \sup_{\|\BJ(\theta-\theta_0)\|\leq n^{-1/2} C}\frac{\pi(\theta)}{\pi(\theta_0)}\\
      &+
      \sup_{\|\BJ(\theta-\theta_0)\|\leq n^{-1/2} C}
      \Big|\frac{\pi(\theta)}{\pi(\theta_0)}-1\Big|
        \\
        +&
\exp\Big\{
    \frac{p}{2}\log \frac{n}{2\pi}+\frac{1}{2}\log |\psi''(\theta_0)|
    \Big\}
    \int_{\|\BJ(\theta-\theta_0)\|>n^{-1/2} C}
    \exp\Big\{
    -\frac{\sqrt{n}}{4} C\|\BJ(\theta-\theta_0)\|
    \Big\}
\frac{\pi(\theta)}{\pi(\theta_0)} \, d\theta\\
        &+
        \exp \big(-\frac{1}{4}\big(C-(1/\sqrt{\epsilon}+1)\sqrt{p}\big)^2 \big).
    \end{aligned}
    $$
\end{theorem}
\begin{proof}
    Let $\tilde{Z}_n(u)=\exp[\Delta_n^T u - \frac{1}{2}\|u\|^2]$.
    Note that $\phi_p(u;\Delta_n,\BI_p)=\tilde{Z}_n(u)\pi(\theta_0)/\int \tilde{Z}_n(u) \pi(\theta_0)\, du$.
    We have
    $$
    \begin{aligned}
        &\int | \pi^*(u) -\phi_p(u;\Delta_n,\BI_p)| \, du
        =
    \int \Big| \frac{
Z_n(u) \pi(\theta_0+n^{-1/2} \BJ^{-1}u)
}{
    \int Z_n(w) \pi(\theta_0+n^{-1/2} \BJ^{-1}w) \, dw
}
        -
        \frac{\tilde{Z}_n(u)\pi(\theta_0)}{\int \tilde{Z}_n(w) \pi(\theta_0)\, dw}
        \Big| \, du
        \\
        \leq&
    \int \Big|
        \frac{
Z_n(u) \pi(\theta_0+n^{-1/2} \BJ^{-1}u)
}{
    \int Z_n(w) \pi(\theta_0+n^{-1/2} \BJ^{-1}w) \, dw
}
        -
        \frac{
Z_n(u) \pi(\theta_0+n^{-1/2} \BJ^{-1}u)
}{
\int \tilde{Z}_n(w) \pi(\theta_0)\, dw
}
        \Big| \, du
        \\
        &+
    \int \Big| 
        \frac{
Z_n(u) \pi(\theta_0+n^{-1/2} \BJ^{-1}u)
}{
\int \tilde{Z}_n(w) \pi(\theta_0)\, dw
}
        -
        \frac{\tilde{Z}_n(u)\pi(\theta_0)}{\int \tilde{Z}_n(w) \pi(\theta_0)\, dw}
        \Big| \, du\\
        =&
\Big| 
1-
        \frac{
    \int Z_n(u) \pi(\theta_0+n^{-1/2} \BJ^{-1}u) \, du
}{
       \int \tilde{Z}_n(u)\pi(\theta_0) \, du
}
        \Big|
        +
        \frac{
    \int \big|
Z_n(u) \pi(\theta_0+n^{-1/2} \BJ^{-1}u)
        -
            \tilde{Z}_n(u) \pi(\theta_0)
        \big| \, du
            }{
            \int \tilde{Z}_n(u)\pi(\theta_0) \, du
        }\\
        \leq&
\Big| 
1-
        \frac{
    \int Z_n(u) \pi(\theta_0+n^{-1/2} \BJ^{-1}u) \, du
}{
       \int \tilde{Z}_n(u)\pi(\theta_0) \, du
}
        \Big|
        +
        \frac{
    \int \big|
Z_n(u) \pi(\theta_0+n^{-1/2} \BJ^{-1}u)
        -
            \tilde{Z}_n(u) \pi(\theta_0)
        \big| \, du
            }{
            \int \tilde{Z}_n(u)\pi(\theta_0) \, du
        }\\
        \leq&
        2\frac{
    \int \big|
Z_n(u) \pi(\theta_0+n^{-1/2} \BJ^{-1}u)
        -
            \tilde{Z}_n(u) \pi(\theta_0)
        \big| \, du
            }{
            \int \tilde{Z}_n(u)\pi(\theta_0) \, du
        }\\
        =&
        2
    \int \Big|
\exp\big\{\log Z_n(u) -\frac{p}{2}\log (2\pi)-\frac{1}{2}\|\Delta_n\|^2\big\}
\frac{\pi(\theta_0+n^{-1/2} \BJ^{-1}u)}{\pi(\theta_0)}
        -
        \phi_p(u;\Delta_n,\BI_p)
        \Big| \, du
    \end{aligned}
    $$

We split the integral into the region $\|u\|\leq C$ and $\|u\|>C$, where $C$ will be specified latter.
Then
\begin{equation}\label{eq:threeTerms}
\begin{aligned}
    &\int \Big|
\exp\big\{\log Z_n(u) -\frac{p}{2}\log (2\pi)-\frac{1}{2}\|\Delta_n\|^2\big\}
\frac{\pi(\theta_0+n^{-1/2} \BJ^{-1}u)}{\pi(\theta_0)}
        -
        \phi_p(u;\Delta_n,\BI_p)
        \Big| \, du
        \\
        \leq &
    \int_{\|u\|\leq C} \Big|
\exp\big\{\log Z_n(u) -\frac{p}{2}\log (2\pi)-\frac{1}{2}\|\Delta_n\|^2\big\}
\frac{\pi(\theta_0+n^{-1/2} \BJ^{-1}u)}{\pi(\theta_0)}
        -
        \phi_p(u;\Delta_n,\BI_p)
        \Big| \, du
        \\
        &+ 
    \int_{\|u\|> C}
\exp\big\{\log Z_n(u) -\frac{p}{2}\log (2\pi)-\frac{1}{2}\|\Delta_n\|^2\big\}
\frac{\pi(\theta_0+n^{-1/2} \BJ^{-1}u)}{\pi(\theta_0)}\, du
        +\int_{\|u\|>C} \phi_p(u;\Delta_n,\BI_p) \, du
        \\
\end{aligned}
\end{equation}

    We deal the three terms of~\eqref{eq:threeTerms} separately.
    Consider the first term. For $\|u\|\leq C$, we have
    $$
    \begin{aligned}
        &\log Z_n(u)-\frac{p}{2}\log (2\pi)-\frac{1}{2}\|\Delta_n\|^2
        =-\frac{p}{2}\log (2\pi)-\frac{1}{2}\|u-\Delta_n\|^2\\
    &-n\Big(\frac{1}{6 n^{3/2}}\myE_{\theta_0}\big(u^T \BJ^{-1}(U-\myE_{\theta_0}U)\big)^3+O(1)\frac{1}{n^2}\|u\|^4 B_{2n}(n^{-1/2}\|u\|)\Big).
    \end{aligned}
    $$
    Hence
    \begin{equation}\label{eq:estimateLikelihood}
        \begin{aligned}
            &\Big|\Big(\log Z_n(u)-\frac{p}{2}\log (2\pi)-\frac{1}{2}\|\Delta_n\|^2\Big)
        -\Big(-\frac{p}{2}\log (2\pi)-\frac{1}{2}\|u-\Delta_n\|^2\Big)\Big|\\
            \leq&
            \frac{1}{6}\Big(
    \frac{1}{n^{1/2}}\|u\|^3 B_{1n}(0)+\frac{1}{n}\|u\|^4 B_{2n}(n^{-1/2}\|u\|)
    \Big)\\
            \leq&
            \frac{1}{6}\Big(
    \frac{1}{n^{1/2}}C^3 B_{1n}(0)+\frac{1}{n}C^4 B_{2n}(n^{-1/2}C)
    \Big).
        \end{aligned}
    \end{equation}
    It follows that
    $$
  \begin{aligned}  
      &\int_{\|u\|\leq C} \Big|
\exp\big\{\log Z_n(u) -\frac{p}{2}\log (2\pi)-\frac{1}{2}\|\Delta_n\|^2\big\}
\frac{\pi(\theta_0+n^{-1/2} \BJ^{-1}u)}{\pi(\theta_0)}
        -
        \phi_p(u;\Delta_n,\BI_p)
        \Big| \, du\\
      \leq&\int_{\|u\|\leq C} \Big|
\exp\big\{\log Z_n(u) -\frac{p}{2}\log (2\pi)-\frac{1}{2}\|\Delta_n\|^2\big\}
        -
        \phi_p(u;\Delta_n,\BI_p)  \Big| 
\frac{\pi(\theta_0+n^{-1/2} \BJ^{-1}u)}{\pi(\theta_0)}
        \, du\\
      &+
      \int_{\|u\|\leq C} \Big|
\frac{\pi(\theta_0+n^{-1/2} \BJ^{-1}u)}{\pi(\theta_0)}-1
      \Big|
        \phi_p(u;\Delta_n,\BI_p)
         \, du\\
\leq&
      \Big|
      \exp\Big\{\frac{1}{6}\big(
    \frac{1}{n^{1/2}}C^3 B_{1n}(0)+\frac{1}{n}C^4 B_{2n}(n^{-1/2}C)
      \big)\Big\}
        -
        1
          \Big| 
      \int_{\|u\|\leq C} 
\frac{\pi(\theta_0+n^{-1/2} \BJ^{-1}u)}{\pi(\theta_0)}
\phi_p(u;\Delta_n,\BI_p)
        \, du\\
      &+
      \int_{\|u\|\leq C} \Big|
\frac{\pi(\theta_0+n^{-1/2} \BJ^{-1}u)}{\pi(\theta_0)}-1
      \Big|
        \phi_p(u;\Delta_n,\BI_p)
         \, du\\
\leq&
      \Big|
      \exp\Big\{\frac{1}{6}\big(
    \frac{1}{n^{1/2}}C^3 B_{1n}(0)+\frac{1}{n}C^4 B_{2n}(n^{-1/2}C)
      \big)\Big\}
        -
        1
          \Big| 
      \sup_{\|\BJ(\theta-\theta_0)\|\leq n^{-1/2} C}\frac{\pi(\theta)}{\pi(\theta_0)}\\
      &+
      \sup_{\|\BJ(\theta-\theta_0)\|\leq n^{-1/2} C}
      \Big|\frac{\pi(\theta)}{\pi(\theta_0)}-1\Big|.
  \end{aligned}
    $$

    Next we deal with the last term of~\eqref{eq:threeTerms}.
Note that $\myE \Delta_n=\textbf{0}_p$ and $\myVar \Delta_n = \BI_p$. By Chebyshev's inequality, for $\epsilon>0$, there is an $M=1/\sqrt{\epsilon}$ such that $$\sup_n\Pr(\|\Delta_n\|\geq M\sqrt{p})<\epsilon.$$
Denote $\mathcal{A}=\{\|\Delta_n\|\leq M\sqrt{p}\}$.
On the event $\mathcal{A}$, for $M_1>0$,
$$
\int_{\|u\|>(M+1)\sqrt{p}+M_1} \phi_p(u;\Delta_n,\BI_p)\, du\leq \int_{\|u\|>M_1+\sqrt{p}} \phi_p(u;\mathbf{0}_p,\BI_p)\, du\leq \exp \big(-\frac{1}{4}M_1^2 \big).
$$
Hence for large $n$ such that $C>(M+1)\sqrt{p}$, we have
$$
\int_{\|u\|>C} \phi_p(u;\Delta_n,\BI_p)\, du\leq \exp \big(-\frac{1}{4}\big(C-(M+1)\sqrt{p}\big)^2 \big).
$$

Now we deal with the second term of~\eqref{eq:threeTerms}.
For $\|u\|\geq C$, by the concavity of $\log Z_n(u)$, we have that
$$
(1-\frac{C}{\|u\|})\log Z_n(0)+\frac{C}{\|u\|}\log Z_n(u)
\leq 
\log Z_n\big(\frac{C}{\|u\|}u\big).
$$
Hence 
$$\log Z_n(u)\leq \frac{\|u\|}{C} \log Z_n(\frac{C}{\|u\|} u).$$
This, combined with~\eqref{eq:estimateLikelihood}, yields
$$
\begin{aligned}
    \log Z_n(u)\leq& 
    \frac{\|u\|}{C}\Big(
    -\frac{1}{2}\big\|\frac{C}{\|u\|}u-\Delta_n \big\|^2+\frac{1}{2}\|\Delta_n\|^2+
    \frac{1}{6}\big(\frac{1}{n^{1/2}}C^3 B_{1n}(0)+\frac{1}{n}C^4 B_{2n}(n^{-1/2}C)\big)
    \Big)\\
    =&
    -\frac{1}{2} C\|u\|+ \Delta_n^T u
    +\frac{\|u\|}{C}\frac{1}{6}\big(\frac{1}{n^{1/2}}C^3 B_{1n}(0)+\frac{1}{n}C^4 B_{2n}(n^{-1/2}C)\big).
\end{aligned}
$$
Hence on the event $\mathcal{A}$, for sufficiently large $n$, we have
$$
\begin{aligned}
    &\log Z_n(u) -\frac{p}{2}\log (2\pi)-\frac{1}{2}\|\Delta_n\|^2\\
    \leq&
-\frac{p}{2}\log (2\pi)
    -\frac{1}{2} C\|u\|+ M\sqrt{p} \| u\|
    +\frac{\|u\|}{C}\frac{1}{6}\big(\frac{1}{n^{1/2}}C^3 B_{1n}(0)+\frac{1}{n}C^4 B_{2n}(n^{-1/2}C)\big)\\
    =&
-\frac{p}{2}\log (2\pi)
    -\frac{1}{2} C\|u\|\Big(1- \frac{2M}{C}\sqrt{p} 
    -\frac{1}{3}\big(\frac{1}{n^{1/2}}C B_{1n}(0)+\frac{1}{n}C^2 B_{2n}(n^{-1/2}C)\big)\Big)\\
    \leq&
-\frac{p}{2}\log (2\pi)
    -\frac{1}{4} C\|u\|.
\end{aligned}
$$
Hence the second term of~\eqref{eq:threeTerms} can be bounded by
$$
\begin{aligned}
    &\int_{\|u\|> C}
\exp\big\{\log Z_n(u) -\frac{p}{2}\log (2\pi)-\frac{1}{2}\|\Delta_n\|^2\big\}
\frac{\pi(\theta_0+n^{-1/2} \BJ^{-1}u)}{\pi(\theta_0)}\, du
\\
    \leq & 
    \int_{\|u\|> C}
\exp\Big\{
-\frac{p}{2}\log (2\pi)
    -\frac{1}{4} C\|u\|
    \Big\}
\frac{\pi(\theta_0+n^{-1/2} \BJ^{-1}u)}{\pi(\theta_0)}\, du\\
    = & 
    \int_{\|\BJ(\theta-\theta_0)\|>n^{-1/2} C}
\exp\Big\{
-\frac{p}{2}\log (2\pi)
    -\frac{\sqrt{n}}{4} C\|\BJ(\theta-\theta_0)\|
    \Big\}
\frac{\pi(\theta)}{\pi(\theta_0)} n^{p/2} |\BJ| \, d\theta\\
    = & 
\exp\Big\{
    \frac{p}{2}\log \frac{n}{2\pi}
    +\frac{1}{2}\log |\psi''(\theta_0)|
    \Big\}
    \int_{\|\BJ(\theta-\theta_0)\|>n^{-1/2} C}
    \exp\Big\{
    -\frac{\sqrt{n}}{4} C\|\BJ(\theta-\theta_0)\|
    \Big\}
\frac{\pi(\theta)}{\pi(\theta_0)} \, d\theta.
\end{aligned}
$$
This proves the theorem.
\end{proof}


\section{Bayes consistency}
For the models more general than the exponential families, the tail behavior of the likelihood is hard to control.
As a result, Bayes consistency is not trivial.
We consider the general case.
Suppose that we observe a random sample $X_1,\ldots, X_n$ from a distribution $P_0$ with densitu $p$ relative to some reference measure $\mu$ on the sample space $(\mathbb{X},\mathbb{A})$. 
Let $P_0^n$ denote the expectation with respect to $X_1,\ldots, X_n$. 
Let $\mu^n$ denote the $n$-fold product measure of $\mu$.
Let $p^n$ denote the density of $P^n$ with respect to $\mu^n$.
Let $\BX^n=(X_1,\ldots, X_n)$ be the pooled data.
Suppose the model space is $\mathcal{P}$.
Given some prior distribution $\Pi$ on the set $\mathcal{P}$, the posterior distribution is the random measure given by
\begin{equation}\label{eq:BayesFormula}
\Pi(B|X_1,\ldots, X_n)=\frac{
    \int_B \prod_{i=1}^n p(X_i) \, d \Pi_n(P)
}{
    \int \prod_{i=1}^n p(X_i) \, d \Pi_n(P)
}.
\end{equation}

To prove the consistency result, i.e., the posterior probability of $\{P:d(P_0, P)>\epsilon\}$ ($d(\cdot,\cdot)$ is certain distance) tends to $0$, we need to lower bound the denominator of~\eqref{eq:BayesFormula} and upper bound the numerator of~\eqref{eq:BayesFormula}.
There is a commonly used method for lower bounding the denominator.
The following lemma is adapted from~\cite{ghosal2000} and~\cite{Shen2001Rates}.
Let 
$$D_{KL}(P||Q)=P\log ({dP}/{dQ}),\quad V(P||Q)=\myVar_P \big(\log(dP/dQ)\big).$$
\begin{lemma}\label{lemma:denominator}
    Let $\alpha>0$ and $\epsilon>0$.
    Let 
    $$A_\epsilon=\{ P:  D_{KL}(P_0, P)\leq \epsilon,\, V(P_0||P)\leq \epsilon\}.$$
Then for every prior probability measure $\Pi$ and every $C>0$, we have
$$
    P_0^n\Big(
    \int_{\mathscr{P}} \Big[\frac{p^n}{p^n_0} (\BX^n ) \Big]^\alpha \, d \Pi(P)
    <
    \Pi(A_\epsilon)
    \exp\big(-(1+C)n\epsilon\big)
    \Big)\leq \frac{\alpha^2}{C^2 n \epsilon}    
$$
\end{lemma}
\begin{proof}
    Without loss of generality, we assume $\Pi(A_{\epsilon})>0$.
    Let $\Pi_{\epsilon}$ be the restriction of $\Pi$ on $A_{\epsilon}$.
    Then
$$
    \begin{aligned}
        &P_0^n\Big(
        \int_{\mathscr{P}} \Big[\frac{p^n}{p^n_0} (\BX^n)\Big]^\alpha \, d \Pi(P)
    <
    \Pi(A_\epsilon)
    \exp\big(-(1+C)n\epsilon\big)
    \Big)\\
        \leq &
    P_0^n\Big(
        \log \int_{\mathscr{P}} \Big[\frac{p^n}{p^n_0} (\BX^n)\Big]^\alpha \, d \Pi_\epsilon (P)
    <
    -(1+C)n\epsilon\Big)\\
        \leq &
    P_0^n\Big(
     \int \alpha \log \frac{p^n}{p^n_0} (\BX^n) \, d \Pi_\epsilon (P)
    <
    -(1+C)n\epsilon\Big)\\
        = &
    P_0^n\Big(
        \sum_{i=1}^n \int \log \frac{p}{p_0} (X_i) \, d \Pi_\epsilon (P)
    <
    -(1+C)n\epsilon/\alpha\Big)\\
        \leq &
    P_0^n\Big(
        \sum_{i=1}^n \int \log \frac{p}{p_0} (X_i) +  D_{KL}(P_0||P)\, d \Pi_\epsilon (P)
    <
    -Cn\epsilon/\alpha\Big)\\
        \leq &
        \frac{\alpha^2}{C^2 n^2 \epsilon^2}
        {n}
        P_0 \Big( \int \log \frac{p}{p_0}  +  D_{KL}(P_0 || P)\, d\Pi_\epsilon (P)  \Big)^2\\
        \leq &
        \frac{\alpha^2}{C^2 n \epsilon^2}
        P_0  \int \Big(\log \frac{p}{p_0}  +  D_{KL}(P_0 || P)\Big)^2\, d\Pi_\epsilon (P)  \\
        = &
        \frac{\alpha^2}{C^2 n \epsilon^2}
          \int P_0\Big(\log \frac{p}{p_0}  +  D_{KL}(P_0 || P)\Big)^2\, d\Pi_\epsilon (P)  \\
        = &
        \frac{\alpha^2}{C^2 n \epsilon^2}
          \int V(P_0|| P)\, d\Pi_\epsilon (P)  
        \leq 
        \frac{\alpha^2}{C^2 n \epsilon}.
    \end{aligned}
$$
\end{proof}
The hard part is the numerator.
\cite{Shen2001Rates} directly upper bound $p^n/p_0^n (X)$ to upper bound the numerator.
\cite{Ghosal2000Asymptotic} imposed a test condition to upper bound the numerator.
If no additional assumption is adopted, the numerator can not be bounded.
In fact, there are counterexamples, see~\cite{diaconis1986consistency}.
\subsection{The work of~\cite{kar10563}}
While the numerator of the posterior distribution is hard to control, a variation of posterior distribution is easier to control.
This work is done by~\cite{kar10563}.

For density $f_1$ and $f_2$, let
$$H(f_1,f_2)=\Big(\int(\sqrt{f_1}-\sqrt{f_2})^2 \, d \mu\Big)^{1/2}=\Big(2-2\int \sqrt{f_1 f_2}\, d \mu \Big)^{1/2},$$
the Hellinger distance of $f_1$ and $f_2$.
For $0<\alpha<1$, Hellinger integral is defined as
$$
\rho_{\alpha}(f_1,f_2)=\int_{\mathcal{X}} f_1^{\alpha} f_2^{1-\alpha} \, d \mu.
$$

For $0<\alpha<1$, define the pseudoposterior distribution $Q$ based on $\Pi$ as
$$
Q^n (A)=\frac{\int_{A} \big[p^n(\BX^n)\big]^{\alpha}\, d\Pi_n(P)}{\int_{\mathscr{P}} \big[p^n(\BX^n)\big]^{\alpha}\, d\Pi_n(P)}.
$$
\begin{theorem}
    Suppose $\Pi_n\Big(A_{\epsilon}\Big)>0$ for every $\epsilon>0$, where
    $$
    A_{\epsilon}=\{P: D_{KL}(P_0,P)\leq \epsilon, \, V(P_0 || P) \leq \epsilon\}.
    $$
    Then for every $\epsilon>0$ and $C>0$
     $$
     \begin{aligned}
         P_0^n \Big\{ Q^n\big( \rho_\alpha (P,P_0)\leq 1-\epsilon\big)\Big\}
         \leq \frac{1}{\Pi(A_{\frac{\epsilon}{2(1+C)}})}\exp (-\frac{1}{2}\epsilon n) +\frac{2(1+C)\alpha^2}{C^2n\epsilon}.
     \end{aligned}
     $$
\end{theorem}
\begin{proof}
Consider the expactation of the numerator,
    $$
    \begin{aligned}
        &P_0^n\int_{\rho_{\alpha}(P,P_0)\leq 1- \epsilon} \Big[ \frac{p^n}{p_0^n} (\BX^n) \Big]^{\alpha} \, d \Pi_n(P)
        \\
        =&
        \int_{\rho_{\alpha}(P,P_0)\leq 1- \epsilon} \int_{\mathcal{X}^n}\Big[ \frac{p^n}{p_0^n} (\BX^n) \Big]^{\alpha} p_0^n (\BX^n)\, d\mu^n \, d \Pi_n(P)\\
        =&
        \int_{\rho_{\alpha}(P,P_0)\leq 1- \epsilon} \int_{\mathcal{X}^n}\Big[ {p^n} (\BX^n) \Big]^{\alpha}  \Big[ p_0^n (\BX^n) \Big]^{1-\alpha} \, d\mu^n \, d \Pi_n(P)\\
        =&
        \int_{\rho_{\alpha}(P,P_0)\leq 1- \epsilon} \big( \rho_{\alpha}(p,p_0) \big)^n \, d \Pi_n(P)\\
        \leq&
        \exp (-\epsilon n).
    \end{aligned}
    $$
    Consider the denominator.
     From Lemma~\ref{lemma:denominator}, on a set $B$ with $P_0^n(B)>1-\alpha^2/(C^2 n \epsilon')$, we have
     $$
     \int_{\mathscr{P}}\Big[\frac{p^n}{p_0^n}(\BX^n)\Big]^{\alpha} \, d\Pi(P)
     \geq \Pi(A_{\epsilon'}) \exp \big(-(1+C)\epsilon' n\big).
     $$
     Hence 
     $$
     \begin{aligned}
         &P_0^n \Big\{ Q^n\big( \rho_\alpha (P,P_0)\leq 1-\epsilon\big)\Big\}\\
         \leq&P_0^n \Big\{ \mathbf{1}_{B} Q^n\big( \rho_\alpha (P,P_0)\leq 1-\epsilon\big)\Big\}+P_0^n (B^C)\\
         \leq& \frac{1}{\Pi(A_{\epsilon'})}\exp (-\epsilon n+(1+C)\epsilon' n) +\frac{\alpha^2}{C^2n\epsilon'}.
     \end{aligned}
     $$
     Let $\epsilon'=\frac{\epsilon}{2(1+C)}$, we have
     $$
     \begin{aligned}
         P_0^n \Big\{ Q^n\big( \rho_\alpha (P,P_0)\leq 1-\epsilon\big)\Big\}
         \leq \frac{1}{\Pi(A_{\frac{\epsilon}{2(1+C)}})}\exp (-\frac{1}{2}\epsilon n) +\frac{2(1+C)\alpha^2}{C^2n\epsilon}.
     \end{aligned}
     $$
\end{proof}
One deficit of the theorem is that it does not satisfactorily cover finite-dimensional models.
When applied to such models, it would yield the rate $1/\sqrt{n}$ times a logarithmic factor rather than $1/\sqrt{n}$ itself.

Next we consider finite-dimensional models.
Let $\{p_{\theta}: \theta\in \Theta\}$ be a family of densities parametrized by a Euclidean parameter $\theta$ running through an open set $\Theta\subset \mathbb{R}^p$. 
Assume that for every $\theta, \theta_1,\theta_2 \in \Theta$ and some $\alpha>0$,
there exists positive constants $C_1,C_2,C_3,C_4$, such that
$$
\begin{aligned}
    &D_{KL}(p_{\theta_0} || p_{\theta})\leq C_1 \|\theta-\theta_0\|^{2\alpha}\\
    &V(p_{\theta_0} || p_{\theta})\leq C_1 \|\theta-\theta_0\|^{2\alpha}\\
    &C_3 \|\theta_1-\theta_2\|^{2\alpha}\leq 1-\rho_{\alpha}(p_{\theta} , p_{\theta_0})\leq C_4 \|\theta_1-\theta_2\|^{2\alpha}\\
    &\\
\end{aligned}
$$
The $C_4$ seems useless, and we can assume that the third inequality only holds locally.
The proof of the following theorem is similar to the corresponding nonparametric one.
\begin{theorem}
    Under the conditions listed previously and $\theta_0$ interior to $\Theta$, then for $M_n\to \infty$,
    $$
    P_0^n \Big\{ Q^n \big( \|\theta-\theta_0\|\geq \frac{M_n}{n^{\frac{1}{2\alpha}}}\big)\Big\}
    \leq
    .
    $$
\end{theorem}
\begin{proof}
    Without loss of generality, we assume $\frac{M_n}{n^{\frac{1}{2\alpha}}}\to 0$, otherwise we replace $M_n$ by a smaller one.
Consider the expactation of the numerator,
    $$
    \begin{aligned}
        &P_0^n\int_{\|\theta-\theta_0\|\geq \frac{M_n}{n^{\frac{1}{2\alpha}}} } \Big[ \frac{p_{\theta}^n}{p_0^n} (\BX^n) \Big]^{\alpha} \, d \Pi_n(\theta)
        \\
        =&
        \int_{\|\theta-\theta_0\|\geq \frac{M_n}{n^{\frac{1}{2\alpha}}} } \int_{\mathcal{X}^n}\Big[ \frac{p^n_{\theta}}{p_0^n} (\BX^n) \Big]^{\alpha} p_0^n (\BX^n)\, d\mu^n \, d \Pi_n(\theta)\\
        =&
        \int_{\|\theta-\theta_0\|\geq \frac{M_n}{n^{\frac{1}{2\alpha}}} } \int_{\mathcal{X}^n}\Big[ {p^n_{\theta}} (\BX^n) \Big]^{\alpha}  \Big[ p_0^n (\BX^n) \Big]^{1-\alpha} \, d\mu^n \, d \Pi_n(\theta)\\
        =&
        \int_{\|\theta-\theta_0\|\geq \frac{M_n}{n^{\frac{1}{2\alpha}}} } \big( \rho_{\alpha}(p_{\theta},p_{\theta_0}) \big)^n \, d \Pi_n(\theta)\\
        =&
        \sum_{j=1}^{+\infty} \int_{\frac{j M_n}{n^{\frac{1}{2\alpha}}} \leq \|\theta-\theta_0\|\leq \frac{(j+1)M_n}{n^{\frac{1}{2\alpha}}} } \big( \rho_{\alpha}(p_{\theta},p_{\theta_0}) \big)^n \, d \Pi_n(\theta)
        \\
        \leq&
        \sum_{j=1}^{+\infty} \int_{\frac{j M_n}{n^{\frac{1}{2\alpha}}} \leq \|\theta-\theta_0\|\leq \frac{(j+1)M_n}{n^{\frac{1}{2\alpha}}} } \big( 1- C_3 (\frac{jM_n}{n^{\frac{1}{2\alpha}}})^{2\alpha} \big)^n \, d \Pi_n(\theta)
        \\
        \lesssim&
        \sum_{j=1}^{+\infty}
        \Big[\frac{(j+1)M_n}{n^{\frac{1}{2\alpha}}}\Big]^p
        \exp[- C_3 \Big(\frac{jM_n}{n^{\frac{1}{2\alpha}}}\Big)^{2\alpha}n]
        \\
        =&
        \sum_{j=1}^{+\infty}
        \Big[\frac{(j+1)M_n}{n^{\frac{1}{2\alpha}}}\Big]^p
        \exp[- C_3 \Big({jM_n}\Big)^{2\alpha}]
    \end{aligned}
    $$
    Consider the denominator.
     From Lemma~\ref{lemma:denominator}, on a set $B$ with $P_0^n(B)>1-\alpha^2/(C^2 n \epsilon')$, we have
     $$
     \int_{\Theta}\Big[\frac{p_{\theta}^n}{p_0^n}(\BX^n)\Big]^{\alpha} \, d\Pi(\theta)
     \geq \Pi(A_{\epsilon'}) \exp \big(-(1+C)\epsilon' n\big)
     \geq \Pi\Big(\Big\{\theta: \|\theta-\theta_0\|\leq (\epsilon'/C_1)^{\frac{1}{2\alpha}}\Big\}\Big) \exp \big(-(1+C)\epsilon' n\big).
     $$
     Let $\epsilon'=\frac{C_3 M_n^{2\alpha}}{2(1+C)n}$, we have
     $$
     \int_{\Theta}\Big[\frac{p_{\theta}^n}{p_0^n}(\BX^n)\Big]^{\alpha} \, d\Pi(\theta)
     \gtrsim \Big[\frac{M_n}{n^{\frac{1}{2\alpha}}}\Big]^p \exp \big(-\frac{1}{2} C_3 M_n^{2\alpha}\big).
     $$
     Hence 
     $$
     \begin{aligned}
         &P_0^n \Big\{ Q^n\big(\|\theta-\theta_0\|\geq \frac{M_n}{n^{\frac{1}{2\alpha}}}\big)\Big\}\\
         \leq&P_0^n \Big\{ \mathbf{1}_{B} Q^n\big( \|\theta-\theta_0\|\geq \frac{M_n}{n^{\frac{1}{2\alpha}}}\big)\Big\}+P_0^n (B^C)\\
         \leq& 
        \sum_{j=1}^{+\infty}
        (j+1)^p
         \exp[- \frac{1}{2}C_3 \Big({jM_n}\Big)^{2\alpha}]
         +
         \frac{2(1+C)\alpha^2}{C^2 C_3 M_n^{2\alpha}}\to 0.
     \end{aligned}
     $$
\end{proof}




\begin{appendices}
    \section{haha1}
    \section{haha2}
\end{appendices}


\section*{References}

\bibliographystyle{apalike}
\bibliography{mybibfile}

\end{document}
